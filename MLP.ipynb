{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import time\n",
    "import plaidml.keras \n",
    "plaidml.keras.install_backend()\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "from keras import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "    lines = np.array(content)\n",
    "    num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = [], [], [], []\n",
    " \n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "        val = img.split(\" \")\n",
    "        pixels = np.array(val, 'float32')\n",
    "        #emotion = ut.to_categorical(emotion, 7)\n",
    "        if 'Training' in usage:\n",
    "            train_labels.append(emotion)\n",
    "            train_images.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            test_labels.append(emotion)\n",
    "            test_images.append(pixels)\n",
    "    except:\n",
    "          print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels) \n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 2304)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (28709, 2304) (28709,)\n",
      "Testing data shape :  (3589, 2304) (3589,)\n",
      "Total number of outputs :  7\n",
      "Output classes :  ['0' '1' '2' '3' '4' '5' '6']\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    " \n",
    "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
    " \n",
    "print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
    " \n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(train_labels)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e8fc22961cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Display the first image in training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ground Truth : {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a9663d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5])\n",
    " \n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_labels[0]))\n",
    " \n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_images[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change from matrix to array of dimension 28x28 to array of dimention 784\n",
    "dimData = np.prod(train_images.shape[1:])\n",
    "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
    "test_data = test_images.reshape(test_images.shape[0], dimData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    " \n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label 0 :  0\n",
      "After conversion to categorical ( one-hot ) :  [ 1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    " \n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0 : ', train_labels[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"llvm_preview_cpu.0\"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = Sequential()\n",
    "model_reg.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "model_reg.add(Dense(512, activation='relu'))\n",
    "\n",
    "model_reg.add(Dense(nClasses, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_reg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 52s - loss: 1.9435 - acc: 0.1320 - val_loss: 1.8818 - val_acc: 0.2494\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 38s - loss: 1.8636 - acc: 0.2419 - val_loss: 1.9700 - val_acc: 0.2148\n",
      "Epoch 3/100\n",
      "18432/28709 [==================>...........] - ETA: 13s - loss: 1.8669 - acc: 0.2242"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4b0ef7073ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_one_hot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/plaidml/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/plaidml/__init__.pyc\u001b[0m in \u001b[0;36mas_ndarray\u001b[0;34m(self, ctx)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                 dtype=_NP_TYPES[self.shape.dtype])\n\u001b[0;32m-> 1244\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m             \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/contextlib.pyc\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/plaidml/__init__.pyc\u001b[0m in \u001b[0;36mmmap_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[0;32m-> 1227\u001b[0;31m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[0m\u001b[1;32m   1228\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n\u001b[1;32m   1229\u001b[0m                     _lib().plaidml_get_shape_element_count(self.shape), self.shape, None)\n",
      "\u001b[0;32m/Users/karthik/miniconda2/lib/python2.7/site-packages/plaidml/__init__.pyc\u001b[0m in \u001b[0;36m_check_err\u001b[0;34m(self, result, func, args)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_reg.fit(train_data, train_labels_one_hot, batch_size=2048, epochs=100, verbose=1,validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = model_reg.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
